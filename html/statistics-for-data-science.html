<!DOCTYPE html>
<html lang="en">
<head>
<title>Statistics for Data Science (University of Waterloo Professional Development)</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="shortcut icon" href="../img/favicon.ico">
<link rel="stylesheet" href="../css/bootstrap.min.css">
</head>
<body>
<div class="container">
    <h1 class="text-center mt-5 mb-5">Statistics for Data Science</h1>
    <p class="text-end mb-5"><em>University of Waterloo Professional Development</em></p>
    <div class="accordion" id="accordionExample">
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingOne">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">Introduction to Statistics for Data Science</button>
            </h2>
            <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <p><a href="../docs/timeline-of-statistics.pdf" download>Timeline of statistics, PDF</a></p>
                    <p><span class="badge rounded-pill bg-secondary">Statistics</span> is the study of how best to collect, analyze, and draw conclusions from data (identify the problem &#8594; collect relevant data &#8594; analyze the data &#8594; form a conclusion).</p>
                    <p>A <span class="badge rounded-pill bg-secondary">summary statistic</span> is a single number summarizing a large amount of data. For instance, the primary results of the study after 1 year could be described by two summary statistics: the proportion of people who had a stroke in the treatment (45/224 = 0.20 = 20%) and control (28/227 = 0.12 = 12%) groups.</p>
                    <p>When recording data, use a <span class="badge rounded-pill bg-secondary">data matrix</span> unless you have a very good reason to use a diferent structure. This structure allows new <span class="badge rounded-pill bg-secondary">cases/observational units</span> to be added as rows or new <span class="badge rounded-pill bg-secondary">variables</span> as new columns:</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-11.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>Types of data:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Quantitative</span> (or <span class="badge rounded-pill bg-secondary">numerical</span>) data deals with numbers and things you can measure objectively (dimensions such as height, width, and length; temperature and humidity; prices; area and volume).
                            <ul>
                                <li><span class="badge rounded-pill bg-secondary">Discrete</span> data is a count of something that cannot be made more precise. Typically, it involves integers (the number of children/adults/pets in your family; measured quantities; results of experiments; numerical values obtained by counting).</li>
                                <li><span class="badge rounded-pill bg-secondary">Continuous</span> data can be divided and reduced to finer and finer levels (you can measure someone's height at progressively more precise scales - meters, centimeters, millimeters, and beyond; values obtained by measuring - e.g. height of all students; all values in a given interval of numbers - e.g. federal spending).</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">Qualitative</span> (or <span class="badge rounded-pill bg-secondary">categorical</span>) data deals with characteristics and descriptors that cannot be easily measured, but can be observed subjectively (personal tastes; textures; attractiveness; colour).
                            <ul>
                                <li><span class="badge rounded-pill bg-secondary">Ordinal</span> data: When items are assigned to categories that have some kind of implicit or natural order, such as "short, medium, or tall", the data is of ordinal nature. Another example is a survey question that asks us to rate an item on a 1 to 10 scale, with 10 being the best. This implies that 10 is better than 9, which is better than 8, and so on.</li>
                                <li><span class="badge rounded-pill bg-secondary">Nominal</span> data: Any categorical data that doesn't have an order (e.g. "blue", "red", "green").</li>
                                <li><span class="badge rounded-pill bg-secondary">Binary</span> data place things in one of two mutually exclusive categories: right/wrong, true/false, or accept/reject. It is nominal data but with only two distinct categories.</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">Other</span> non-numerical data such as text or video data.</li>
                    </ul>
                    <p>Broadly speaking, when you measure something and give it a number value, you create <span class="badge rounded-pill bg-secondary">quantitative</span> data. When you classify or judge something, you create <span class="badge rounded-pill bg-secondary">qualitative</span> data.</p>
                    <p>Relationships between data:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Independent variables</span>: If two variables are not associated, then they are said to be independent. That is, two variables are independent if there is no evident relationship between the two.</li>
                        <li><span class="badge rounded-pill bg-secondary">Associated, or dependent</span>: When two variables show some connection with one another, they are called associated variables. Associated variables can also be called dependent variables and vice-versa.</li>
                        <li><span class="badge rounded-pill bg-secondary">Positive association</span>: Two variables are said to be positively associated when they have a linear relationship with a positive slope. That means when the value of one variables increases, the value of the other variable increases as well. For example, the amount people spend is positively associated with the money people make, if we assume that people who earn more spend more.</li>
                        <li><span class="badge rounded-pill bg-secondary">Negative association</span>: When the value of a variable goes down when the value of another variable goes up. This is often characterized by a downward trend when the variables are plotted.</li>
                    </ul>
                    <p>A <span class="badge rounded-pill bg-secondary">scatterplot</span> provides a case-by-case view of data for two numerical variables:</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-1.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>When we suspect one variable might causally affect another, we label the first variable the <span class="badge rounded-pill bg-secondary">explanatory</span> variable and the second the <span class="badge rounded-pill bg-secondary">response</span> variable. Is federal spending, on average, higher or lower in areas with high rates of poverty? If we suspect poverty might affect spending, then poverty is the explanatory variable and federal spending is the response variable in the relationship.</p>
                    <p>Labeling variables as explanatory and response <span class="badge rounded-pill bg-secondary">does not guarantee</span> the relationship between them is causal, even if there is an association (also known as a <span class="badge rounded-pill bg-secondary">correlation</span>) between the two variables. It is also important to note that causation is an <span class="badge rounded-pill bg-secondary">asymmetric</span> relation ("X causes Y" is a different statement than "Y causes X"), whereas correlation is a <span class="badge rounded-pill bg-secondary">symmetric</span> relation ("X is correlated with Y" is an equivalent statement to "Y is correlated with X").</p>
                    <p>In statistics, a <span class="badge rounded-pill bg-secondary">confounding</span> variable is a variable that influences both the dependent variable and independent variable giving rise to a misleading association. Confounding is a causal concept and a confounding variable is also known as a <span class="badge rounded-pill bg-secondary">confounding factor</span>, a <span class="badge rounded-pill bg-secondary">lurking variable</span>, or a <span class="badge rounded-pill bg-secondary">confounder</span>. Suppose an observational study tracked sunscreen use and skin cancer, and it was found that the more sunscreen someone used, the more likely the person was to have skin cancer. Some previous research tells us that using sunscreen actually reduces skin cancer risk, so maybe there is another variable that can explain this hypothetical association between sunscreen usage and skin cancer. One important piece of information that is absent is sun exposure. If someone is out in the sun all day, she is more likely to use sunscreen and more likely to get skin cancer. Sun exposure is what is called a confounding variable, which is a variable that is correlated with both the explanatory and response variables.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-12.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p><span class="badge rounded-pill bg-secondary">Collinearity</span> (or <span class="badge rounded-pill bg-secondary">multicollinearity/ill-conditioning</span>) occurs when independent variables in a regression are so highly correlated that it becomes difficult or impossible to distinguish their individual effects on the dependent variable.</p>
                    <p>Data collection:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Observational studies</span> can provide evidence of a naturally occurring association between variables, but they cannot by themselves show a causal connection. For example, data may be collected via surveys, obtaining records (e.g. medical or company records), or by following a cohort of similar individuals as part of a study. In each of these situations, researchers merely observe the data as it arises. Hence, an observational study is conducted when data is collected in a way that does not directly interfere with how the data arises. Data where no treatment has been explicitly applied (or explicitly withheld) is called <span class="badge rounded-pill bg-secondary">observational data</span>.</li>
                        <li>When the possibility of a causal connection needs to be investigated, an <span class="badge rounded-pill bg-secondary">experiment</span> can be conducted. There are both explanatory and response variables in this case. To check if there really is a causal connection between the explanatory variable and the response, a sample of individuals are identified and split into groups. The individuals in each group are assigned a treatment. In statistics, a <span class="badge rounded-pill bg-secondary">treatment</span> is a generic term which refers to the specifics of how each group is handled for the purposes of an experiment.</li>
                    </ul>
                    <p>Generally, data in observational studies are collected only by monitoring what occurs, while experiments require the primary explanatory variable in a study be assigned for each subject by the researchers. Making causal conclusions based on experiments is often reasonable. However, making the same causal conclusions based on observational data can be unreliable and is not recommended. Thus, observational studies are generally only sufficient to show associations.</p>
                    <div class="row">
                        <div class="col-md"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-2.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></div>
                        <div class="col-md"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-3.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></div>
                        <div class="col-md"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-4.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></div>
                        <div class="col-md"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-5.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></div>
                    </div>
                    <div class="row">
                        <div class="col-md"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-6.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></div>
                        <div class="col-md"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-7.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></div>
                    </div>
                    <p>This is an experiment, as the researchers assigned the volunteers to a treatment group (beer or water).</p>
                    <p>Forms of observational studies:</p>
                    <ul>
                        <li>A <span class="badge rounded-pill bg-secondary">prospective study</span> identifes individuals and collects information as events unfold. For instance, medical researchers may identify and follow a group of patients over many years to assess the possible infuences of behavior on cancer risk. This prospective study recruits registered nurses and then collects data from them using questionnaires.</li>
                        <li><span class="badge rounded-pill bg-secondary">Retrospective studies</span> collect data after events have taken place, e.g. researchers may review past events in medical records.</li>
                    </ul>
                    <p>Studies where the researchers assign treatments to cases are called <span class="badge rounded-pill bg-secondary">experiments</span>. When this assignment includes randomization, e.g. using a coin flip to decide which treatment a patient receives, it is called a <span class="badge rounded-pill bg-secondary">randomized experiment</span>. Randomized experiments are fundamentally important when trying to show a causal connection between two variables. They are generally built on four principles:</p>
                    <ol>
                        <li><span class="badge rounded-pill bg-secondary">Controlling</span>. Researchers assign treatments to cases, and they do their best to control any other differences in the groups. Suppose a farmer wishes to evaluate a new fertilizer. She uses the new fertilizer on one field of crops (A), while using her current fertilizer on another field of crops (B). The irrigation system on field A has recently been repaired and provides adequate water to all of the crops, while the system on field B will not be repaired until next season. She concludes that the new fertilizer is far superior. The problem with this experiment is that the farmer has neglected to control for the effect of the differences in irrigation. This leads to <span class="badge rounded-pill bg-secondary">experimental bias</span>, the favoring of certain outcomes over others. To avoid this bias, the farmer should have tested the new fertilizer in identical conditions to the control group, which did not receive the treatment.</li>
                        <li><span class="badge rounded-pill bg-secondary">Randomization</span>. Researchers randomize patients into treatment groups to account for variables that cannot be controlled. For example, some patients may be more susceptible to a disease than others due to their dietary habits. Using randomization is the most reliable method of creating <span class="badge rounded-pill bg-secondary">homogeneous treatment groups</span>, without involving any potential biases.</li>
                        <li><span class="badge rounded-pill bg-secondary">Replication</span>. The more cases researchers observe, the more accurately they can estimate the effect of the explanatory variable on the response. In a single study, we replicate by collecting a suffciently large sample. Additionally, a group of scientists may replicate an entire study to verify an earlier finding. </li>
                        <li><span class="badge rounded-pill bg-secondary">Blocking</span>. Researchers sometimes know or suspect that variables, other than the treatment, influence the response. Under these circumstances, they may first group individuals based on this variable into blocks and then randomize cases within each block to the treatment groups. This strategy is often referred to as blocking. For instance, if we are looking at the effect of a drug on heart attacks, we might first split patients in the study into low-risk and high-risk blocks, then randomly assign half the patients from each block to the control group and the other half to the treatment group. This strategy ensures each treatment group has an equal number of low-risk and high-risk patients.</li>
                    </ol>
                    <p>A <span class="badge rounded-pill bg-secondary">population</span> is a collection of people, items, or events and includes all members of a defined group that we are studying or collecting information on for data driven decisions.</p>
                    <p>A <span class="badge rounded-pill bg-secondary">sample</span> is a small subset or fraction of a population.</p>
                    <p>A <span class="badge rounded-pill bg-secondary">parameter</span> is any summary number, like an average or percentage, that describes the entire population. For example, the population mean <span class="badge rounded-pill bg-secondary">μ</span> and the population proportion <span class="badge rounded-pill bg-secondary">p</span> are two population parameters.</p>
                    <p>A sample is a finite subset selected from the population with the objective of investigating its properties. The number of units in the sample is known as the <span class="badge rounded-pill bg-secondary">sample size</span>. A sample helps us draw conclusions about the full population. There are 2 key properties of a properly selected sample:</p>
                    <ol>
                        <li>The sample is <span class="badge rounded-pill bg-secondary">randomly</span> selected. A random sample is a group or set chosen from a larger population in a random manner that allows for each member of the larger group to have an equal chance of being chosen. What if we picked a sample by hand? It is entirely possible that the sample could be skewed to that person's interests, which may be entirely unintentional. This introduces bias into a sample.</li>
                        <li>The sample is a <span class="badge rounded-pill bg-secondary">representative</span> sample. A representative sample is a group or set chosen from a larger statistical population that adequately replicates the larger group according to whatever characteristic or quality is under study.</li>
                    </ol>
                    <p>However, although random sampling helps minimize bias, there are still ways in which bias can arise:</p>
                    <ul>
                        <li>In cases of surveys where the non-response rate is high - even if people are picked at random - caution must be taken. For instance, if only 30% of the people randomly sampled for a survey actually respond, then it is unclear whether the results are representative of the entire population. This <span class="badge rounded-pill bg-secondary">non-response bias</span> can skew results.</li>
                        <li>In <span class="badge rounded-pill bg-secondary">convenience samples</span>, only individuals easily accessible are included in the sample. For instance, if a political survey is performed by stopping people walking on Bay Street, this will not represent all of the city of Toronto.</li>
                    </ul>
                    <p>Sampling methods:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Simple random sampling</span>: Consider the salaries of Major League Baseball (MLB) players, where each player is a member of one of the league's 30 teams. To take a simple random sample of 120 baseball players and their salaries, we could write the names of that season's several hundreds of players onto slips of paper, drop the slips into a bucket, shake the bucket around until we are sure the names are all mixed up, then draw out slips until we have the sample of 120 players. In general, a sample is referred to as "simple random" if each case in the population has an equal chance of being included in the final sample and knowing that a case is included in a sample does not provide useful information about which other cases are included.<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-8.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></li>
                        <li><span class="badge rounded-pill bg-secondary">Stratified sampling</span>: The population is divided into groups called <span class="badge rounded-pill bg-secondary">strata</span>. The strata are chosen so that similar cases are grouped together, then a second sampling method, usually simple random sampling, is employed within each <span class="badge rounded-pill bg-secondary">stratum</span>. In the baseball salary example, the teams could represent the strata, since some teams have a lot more money. Then we might randomly sample 4 players from each team for a total of 120 players. Stratifed sampling is especially useful when the cases in each stratum are very similar with respect to the outcome of interest. We might get a more stable estimate for the subpopulation in a stratum if the cases are very similar, leading to more precise estimates within each group. When we combine these estimates into a single estimate for the full population, that population estimate will tend to be more precise since each individual group estimate is itself more precise.<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-9.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></li>
                        <li><span class="badge rounded-pill bg-secondary">Cluster sampling</span>: In a cluster sample, we break up the population into many groups, called <span class="badge rounded-pill bg-secondary">clusters</span>. Then we sample a fixed number of clusters and include all observations from each of those clusters in the sample. It is important to note that, unlike with the strata in stratified sampling, the clusters should be microcosms, rather than subsections, of the population. Each cluster should be heterogeneous. Cluster sampling is most helpful when there is a lot of case-to-case variability within a cluster but the clusters themselves don't look very different from one another.<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-13.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></li>
                        <li><span class="badge rounded-pill bg-secondary">Multistage sampling</span>: A multistage sample is like a cluster sample, but rather than keeping all observations in each cluster, we collect a random sample within each selected cluster.<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-14.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></li>
                    </ul>
                    <p>Please note that although useful in certain circumstances, the use of stratified or cluster sampling can still be very subjective and can introduce bias into the sample.</p>
                    <p><span class="badge rounded-pill bg-secondary">Bias</span> is the intentional or unintentional favouring of one group or outcome over other potential groups or outcomes in the population:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Selection bias</span>: The bias that results from an unrepresentative sample.
                            <ul>
                                <li><span class="badge rounded-pill bg-secondary">Undercoverage bias</span>: Occurs when some members of the population are inadequately represented in the sample.</li>
                                <li><span class="badge rounded-pill bg-secondary">Non-response bias</span>: Bias that results when respondents differ in meaningful ways from non-respondents.</li>
                                <li><span class="badge rounded-pill bg-secondary">Voluntary bias</span>: Sample members are self-selected volunteers.</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">Response bias</span>: The bias that results from problems in the measurement process.
                            <ul>
                                <li><span class="badge rounded-pill bg-secondary">Leading questions</span>: Questions that encourage the expected answer.</li>
                                <li><span class="badge rounded-pill bg-secondary">Social desirability</span>: Responses may be biased toward what the respondents believe is socially desirable.</li>
                            </ul>
                        </li>
                    </ul>
                    <p>Most experiments try to determine whether some type of experimental treatment (or important factor) has a significant effect on an outcome. For example, does zinc help to reduce the length of a cold? Subjects who are chosen to participate in the experiment are typically divided into two groups: a treatment group and a control group. The <span class="badge rounded-pill bg-secondary">treatment group</span> consists of participants who receive the experimental treatment whose effect is being studied (in this case, zinc tablets). The <span class="badge rounded-pill bg-secondary">control group</span> consists of participants who do not receive the experimental treatment being studied. Instead, they get a placebo (a fake treatment - e.g. a sugar pill); a standard, nonexperimental treatment (such as vitamin C, in the zinc study); or no treatment at all, depending on the situation. After the experiment has been performed, the responses of those in the treatment group are compared with the responses from the control group to look for differences that are statistically significant (i.e. unlikely to have occurred just by chance). The study is ideally <span class="badge rounded-pill bg-secondary">double-blind</span> - researchers who interact with the participants and the participants themselves are all unaware of which group they belong to.</p>
                    <p>A <span class="badge rounded-pill bg-secondary">placebo</span> is a fake treatment, such as a sugar pill used in a medical trial. Placebos are given to the control group to account for a psychological phenomenon called the placebo effect, in which patients receiving a fake treatment still report having a response, as if it were the real treatment. By measuring the placebo effect in the control group, you can assess what portion of the reports from the treatment group were due to a real physical effect and what portion were likely due to the placebo effect.</p>
                    <p><span class="badge rounded-pill bg-secondary">Mean</span>: The average of a set of numbers. The mean is a common way to measure the center of a distribution of data. To find the mean number of characters in set of emails, we add up all the character counts and divide by the number of emails.</p>
                    <p><span class="badge rounded-pill bg-secondary">Median</span>: The value in middle of a sorted list. If there are an even number of observations, there will be two values in the middle of list and the median is calculated as the average of these two numbers.</p>
                    <p><span class="badge rounded-pill bg-secondary">Outliers</span> are values that are unusual compared to the rest of the dataset (i.e. especially small or large in numerical value). If we were to find the average salary of 5 employees, whose salaries are $40k, $50k, $45k, $40k and $100k, we compute mean to be sum of salaries divided by 5 which is $55k. However, this isn't the best representation of the group because most of the salaries are between $40k and $50k. The <span class="badge rounded-pill bg-secondary">mean</span> is skewed by the one large salary ($100k). In this situation we would typically use a better measure of central tendency, such as the <span class="badge rounded-pill bg-secondary">median</span>. Examining data for outliers serves many useful purposes, including identifying strong skew in the distribution, identifying possible data collection or data entry errors, and providing insight into interesting properties of the data.</p>
                    <p><span class="badge rounded-pill bg-secondary">Variance</span>: A measure of the variability of the data. Roughly the average squared distance from the mean.</p>
                    <p><span class="badge rounded-pill bg-secondary">Standard deviation</span>: Roughly describes how far away the typical observation is from the mean; the distance is called deviation. Usually about 70% of the data will be within one standard deviation of the mean and about 95% will be within two standard deviations. The standard deviation is also the square root of the variance.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-10.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>Figure 2.9 shows three distributions that look quite different, but all have the same mean, variance, and standard deviation. Using modality, we can distinguish between the first plot (bimodal) and the last two (unimodal). Using skewness, we can distinguish between the last plot (right skewed) and the first two. While a picture, like a histogram, tells a more complete story, we can use modality and shape (symmetry/skew) to characterize basic information about a distribution:</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-28.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>A <span class="badge rounded-pill bg-secondary">dot plot</span> is a one-variable scatterplot:</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-25.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-26.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>Dot plots show the exact value for each observation. This is useful for small data sets, but they can become hard to read with larger samples. Rather than showing the value of each observation, we prefer to think of the value as belonging to a <span class="badge rounded-pill bg-secondary">bin</span>. For example, in the loan50 data set, we created a table of counts for the number of loans with interest rates between 5.0% and 7.5%, then the number of loans with rates between 7.5% and 10.0%, and so on. Observations that fall on the boundary of a bin (e.g. 10.00%) are allocated to the lower bin. <span class="badge rounded-pill bg-secondary">Histograms</span> provide a view of the <span class="badge rounded-pill bg-secondary">data density</span>. Higher bars represent where the data are relatively more common. Histograms are especially convenient for describing the <span class="badge rounded-pill bg-secondary">shape</span> of the data distribution. The chosen <span class="badge rounded-pill bg-secondary">bin width</span> can alter the story the histogram is telling. When data trail off in one direction, the distribution has a <span class="badge rounded-pill bg-secondary">long tail</span>. If a distribution has a long left tail, it is <span class="badge rounded-pill bg-secondary">left skewed</span>. If a distribution has a long right tail, it is <span class="badge rounded-pill bg-secondary">right skewed</span>. In addition to looking at whether a distribution is skewed or <span class="badge rounded-pill bg-secondary">symmetric</span>, histograms can be used to identify modes. A <span class="badge rounded-pill bg-secondary">mode</span> is represented by a prominent peak in the distribution.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-27.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-15.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-16.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>Unimodal and right skewed, with a potentially unusual observation at 60 hours/week.</p>
                    <p>A <span class="badge rounded-pill bg-secondary">box plot</span> summarizes a data set using five statistics while also plotting unusual observations. Figure 2.10 provides a vertical dot plot alongside a box plot of the interest rate variable from the loan50 data set:</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-17.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>The most common definition of a <span class="badge rounded-pill bg-secondary">percentile</span> is a number where a certain percentage of scores fall below that number. You might know that you scored 67 out of 90 on a test. But that figure has no real meaning unless you know what percentile you fall into. If you know that your score is in the 90th percentile, that means you scored better than 90% of people who took the test.</p>
                    <p>The 25th percentile is also called the <span class="badge rounded-pill bg-secondary">first quartile</span>, Q1. The 50th percentile is also called the <span class="badge rounded-pill bg-secondary">median</span>. The 75th percentile is also called the <span class="badge rounded-pill bg-secondary">third quartile</span>, Q3. Between Q1 and Q3 is the middle 50% of the data. The range these data span is called the <span class="badge rounded-pill bg-secondary">interquartile range</span>, or the IQR (IQR = Q3 - Q1).</p>
                    <p>The box in a <span class="badge rounded-pill bg-secondary">box plot</span> represents the middle 50% of the data, and the thick line in the box is the median. Whiskers of a box plot can extend up to 1.5 x IQR away from the quartiles: max upper whisker reach = Q3 + 1.5 x IQR, max lower whisker reach = Q1 - 1.5 x IQR (IQR: 20 - 10 = 10, max upper whisker reach = 20 + 1.5 x 10 = 35, max lower whisker reach = 10 - 1.5 x 10 = -5). A potential outlier is defined as an observation beyond the maximum reach of the whiskers. It is an observation that appears extreme relative to the rest of the data.</p>
                    <p>For skewed distributions it is often more helpful to use <span class="badge rounded-pill bg-secondary">median</span> and <span class="badge rounded-pill bg-secondary">IQR</span> to describe the center and spread; for symmetric distributions it is often more helpful to use the <span class="badge rounded-pill bg-secondary">mean</span> and <span class="badge rounded-pill bg-secondary">SD</span> to describe the center and spread. If the distribution is symmetric, center is often defined as the mean (mean ~ median), if the distribution is skewed or has extreme outliers, center is often defined as the median (<span class="badge rounded-pill bg-secondary">right-skewed</span>: mean &gt; median, <span class="badge rounded-pill bg-secondary">left-skewed</span>: mean &lt; median). The median and IQR are called <span class="badge rounded-pill bg-secondary">robust statistics</span> because extreme observations have little effect on their values: moving the most extreme value generally has little influence on these statistics. On the other hand, the mean and standard deviation are more heavily influenced by changes in extreme observations, which can be important in some situations.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-18.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>A table that summarizes data for two categorical variables is called a <span class="badge rounded-pill bg-secondary">contingency table</span>. Each value in the table represents the number of times a particular combination of variable outcomes occurred.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-19.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>A <span class="badge rounded-pill bg-secondary">bar plot</span> is a common way to display a single categorical variable. A bar plot where proportions instead of frequencies are shown is called a <span class="badge rounded-pill bg-secondary">relative frequency bar plot</span>.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-20.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p><span class="badge rounded-pill bg-secondary">Bar plots</span> are used for displaying distributions of categorical variables, while <span class="badge rounded-pill bg-secondary">histograms</span> are used for numerical variables. The x-axis in a histogram is a number line, hence the order of the bars cannot be changed, while in a bar plot the categories can be listed in any order (though some orderings make more sense than others, especially for ordinal variables).</p>
                    <p><span class="badge rounded-pill bg-secondary">Stacked bar plot</span> is a graphical display of contingency table information, for counts. <span class="badge rounded-pill bg-secondary">Side-by-side bar plot</span> displays the same information by placing bars next to, instead of on top of, each other. <span class="badge rounded-pill bg-secondary">Standardized stacked bar plot</span> is a graphical display of contingency table information, for proportions.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-29.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"><img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-30.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>A <span class="badge rounded-pill bg-secondary">mosaic plot</span> is a visualization technique suitable for contingency tables that resembles a standardized stacked bar plot with the benefit that we still see the relative group sizes of the primary variable as well.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-21.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p><span class="badge rounded-pill bg-secondary">Pie charts</span> can be useful for giving a high-level overview to show how a set of cases break down. However, it is also diffcult to decipher details in a pie chart. While pie charts can be useful, we prefer <span class="badge rounded-pill bg-secondary">bar plots</span> for their ease in comparing groups.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-31.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>Some of the more interesting investigations can be considered by examining <span class="badge rounded-pill bg-secondary">numerical data</span> across groups. The <span class="badge rounded-pill bg-secondary">side-by-side box plot</span> is a traditional tool for comparing across groups. Another useful plotting method uses <span class="badge rounded-pill bg-secondary">hollow histograms</span> to compare numerical data across groups. These are just the outlines of histograms of each group put on the same plot.</p>
                    <img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-32.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">
                    <p>The <span class="badge rounded-pill bg-secondary">weighted mean</span> is the same as the mean, except that it is influenced more by some observations than others. We assign weights to observations as a sort of way of describing its relative importance. In many applications, there are natural choices for weights. For example, in the county data set, population is a natural weighting factor. We'll use w<sub>1</sub> to represent the population of the first county, w<sub>2</sub> to represent the population of the second county, and so on. The label x<sub>1</sub> will represent the average income of county 1, x<sub>2</sub> for the average income of county 2, and so on. Then the mean weighted by population can be written as<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-22.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science">(this equation represents the <span class="badge rounded-pill bg-secondary">weighted mean</span> of income, where the weights are given by the population values).</p>
                    <p>The weighed mean of observations x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub> using weights w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub> is given by<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-23.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></p>
                    <p>The simple mean is a weighted mean where all the weights are 1:<img src="../img/statistics-for-data-science/introduction-to-statistics-for-data-science-24.PNG" class="mx-auto d-block" alt="Introduction to Statistics for Data Science"></p>
                </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingTwo">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="true" aria-controls="collapseTwo">Probability</button>
            </h2>
            <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <h2 class="h4">Probability</h2>
                    <p>We often frame probability in terms of a <span class="badge rounded-pill bg-secondary">random process</span> giving rise to an <span class="badge rounded-pill bg-secondary">outcome</span>. The <span class="badge rounded-pill bg-secondary">probability</span> of an outcome is the proportion of times the outcome would occur if we observed the random process an infinite number of times. Probability is defined as a proportion, and it always takes values between 0 and 1 (inclusively). It may also be displayed as a percentage between 0% and 100%.</p>
                    <h2 class="h4">Disjoint or mutually exclusive outcomes</h2>
                    <p>Two outcomes are called <span class="badge rounded-pill bg-secondary">disjoint</span> or <span class="badge rounded-pill bg-secondary">mutually exclusive</span> if both cannot happen at the same time. For instance, if we roll a die one time, the outcomes 1 and 2 are disjoint since they cannot both occur. On the other hand, the outcomes 1 and "rolling an odd number" are not disjoint since both occur if the outcome of the roll is a 1.</p>
                    <h3 class="h5" id="addition-rule">Addition rule of disjoint outcomes</h3>
                    <p>If A<sub>1</sub> and A<sub>2</sub> represent two disjoint outcomes, then the probability that one of them occurs is given by<img src="../img/statistics-for-data-science/probability-2.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <p>If there are many disjoint outcomes A<sub>1</sub>, ..., A<sub>k</sub>, then the probability that one of these outcomes will occur is<img src="../img/statistics-for-data-science/probability-3.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <p>Data scientists rarely work with individual outcomes and instead consider sets or collections of outcomes. Let A represent the event where a die roll results in 1 or 2 and B represent the event that the die roll is a 4 or a 6. We write A as the set of outcomes {1, 2} and B = {4, 6}. These sets are commonly called <span class="badge rounded-pill bg-secondary">events</span>. Because A and B have no elements in common, they are <span class="badge rounded-pill bg-secondary">disjoint events</span>. The <span class="badge rounded-pill bg-secondary">Addition Rule</span> applies to both disjoint outcomes and disjoint events. The probability that one of the disjoint events A or B occurs is the sum of the separate probabilities (P(A or B) = P(A) + P(B) = 1/3 + 1/3 = 2/3).</p>
                    <h2 class="h4">Probabilities when events are not disjoint</h2>
                    <img src="../img/statistics-for-data-science/probability-6.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The events that a teen went to college or not are disjoint. It is not possible that a teen both attended and did not attend college at the same time. However, the events that a teen went to college (or not) is not disjoint with the event that a parent went to college (or not) and both may happen at the same time. If we simply attempt to add the probabilities of the events, and the events are not mutually exclusive, we may be double counting them. Let's consider the probability that a teen attends college and/or their parent has a degree:</p>
                    <img src="../img/statistics-for-data-science/probability-8.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-9.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-52.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-53.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-54.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-5.PNG" class="mx-auto d-block" alt="Probability">
                    <h3 class="h5">General addition rule</h3>
                    <p>If A and B are any two events, disjoint or not, then the probability that at least one of them will occur is<img src="../img/statistics-for-data-science/probability-1.PNG" class="mx-auto d-block" alt="Probability">where P(A and B) is the probability that both events occur.</p>
                    <p>If the events are <span class="badge rounded-pill bg-secondary">mutually exclusive</span>, then <span class="badge rounded-pill bg-secondary">P(A∩B)=0</span> (see <a href="#addition-rule">Addition rule of disjoint outcomes</a>):</p>
                    <img src="../img/statistics-for-data-science/probability-11.PNG" class="mx-auto d-block" alt="Probability">
                    <p><span class="badge rounded-pill bg-secondary">"or" is inclusive</span>: When we write "or" in statistics, we mean "and/or" unless we explicitly state otherwise. Thus, A or B occurs means A, B, or both A and B occur.</p>
                    <h2 class="h4">Probability distributions</h2>
                    <p>A <span class="badge rounded-pill bg-secondary">probability distribution</span> is a table of all disjoint outcomes and their associated probabilities:</p>
                    <img src="../img/statistics-for-data-science/probability-14.PNG" class="mx-auto d-block" alt="Probability">
                    <p>A probability distribution is a list of the possible outcomes with corresponding probabilities that satisfies three rules:</p>
                    <ol>
                        <li>The outcomes listed must be disjoint.</li>
                        <li>Each probability must be between 0 and 1.</li>
                        <li>The probabilities must total 1.</li>
                    </ol>
                    <p>Probability distributions can also be summarized in a bar plot:</p>
                    <img src="../img/statistics-for-data-science/probability-51.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-50.PNG" class="mx-auto d-block" alt="Probability">
                    <h2 class="h4">Complement of an event</h2>
                    <p>Rolling a die produces a value in the set {1, 2, 3, 4, 5, 6}. This set of all possible outcomes is called the <span class="badge rounded-pill bg-secondary">sample space (S)</span> for rolling a die. We often use the sample space to examine the scenario where an event does not occur.</p>
                    <p>Let D = {2, 3} represent the event that the outcome of a die roll is 2 or 3. Then the <span class="badge rounded-pill bg-secondary">complement</span> of D represents all outcomes in our sample space that are not in D, which is denoted by D<sup>c</sup> = {1, 4, 5, 6}. That is, D<sup>c</sup> is the set of all possible outcomes not already included in D.</p>
                    <p>The complement of event A is denoted A<sup>c</sup>, and A<sup>c</sup> represents all outcomes not in A. A and A<sup>c</sup> are mathematically related:</p>
                    <img src="../img/statistics-for-data-science/probability-12.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-13.PNG" class="mx-auto d-block" alt="Probability">
                    <h2 class="h4">Independence</h2>
                    <p>Two processes are <span class="badge rounded-pill bg-secondary">independent</span> if knowing the outcome of one provides no useful information about the outcome of the other. For instance, flipping a coin and rolling a die are two independent processes - knowing the coin was heads does not help determine the outcome of a die roll. On the other hand, stock prices usually move up or down together, so they are not independent.</p>
                    <h3 class="h5" id="multiplication-rule">Multiplication rule for independent processes</h3>
                    <p>If A and B represent events from two different and independent processes, then the probability that both A and B occur can be calculated as the product of their separate probabilities:</p>
                    <img src="../img/statistics-for-data-science/probability-17.PNG" class="mx-auto d-block" alt="Probability">
                    <p>Similarly, if there are k events A<sub>1</sub>, ..., A<sub>k</sub> from k independent processes, then the probability they all occur is<img src="../img/statistics-for-data-science/probability-18.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <p>Suppose the variables handedness and sex are independent, i.e. knowing someone's sex provides no useful information about their handedness and vice-versa. Then we can compute whether a randomly selected person is right-handed and female using the <span class="badge rounded-pill bg-secondary">Multiplication Rule</span> (P(right-handed and female) = P(right-handed) &times; P(female) = 0.91 &times; 0.50 = 0.455)</p>
                    <p>Let's simulate two independent events: rolling two dice, and then calculate the probability that both dice yield a 6:</p>
                    <img src="../img/statistics-for-data-science/probability-19.PNG" class="mx-auto d-block" alt="Probability">
                    <p>According to the multiplication rule<img src="../img/statistics-for-data-science/probability-20.PNG" class="mx-auto d-block" alt="Probability">which is close to the number obtained from the simulation.</p>
                    <p>We say that two events A and B are independent if they satisfy P(A and B) = P(A) &times; P(B).</p>
                    <img src="../img/statistics-for-data-science/probability-44.PNG" class="mx-auto d-block" alt="Probability">
                    <h2 class="h4">Defining conditional probability</h2>
                    <img src="../img/statistics-for-data-science/probability-21.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The probability that a random teenager from the dataset attended college and that at least one of the teen's parents has a college degree is 231 out of 280 cases:</p>
                    <img src="../img/statistics-for-data-science/probability-22.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The probability that a random teenager from the dataset did not attend college and that at least one of the teen’s parents has a college degree is 49 out of 280 cases:</p>
                    <img src="../img/statistics-for-data-science/probability-23.PNG" class="mx-auto d-block" alt="Probability">
                    <p>These are <span class="badge rounded-pill bg-secondary">conditional probabilities</span> because we computed the probability under a condition: a parent has a college degree; the conditional probabilities add up to 1.</p>
                    <p>The conditional probability of the outcome of interest A given condition B is computed as the following:</p>
                    <img src="../img/statistics-for-data-science/probability-24.PNG" class="mx-auto d-block" alt="Probability">
                    <p>Applying the general definition to our example:</p>
                    <img src="../img/statistics-for-data-science/probability-25.PNG" class="mx-auto d-block" alt="Probability">
                    <h2 class="h4">Marginal and joint probabilities</h2>
                    <p>If a probability is based on a single variable, it is a <span class="badge rounded-pill bg-secondary">marginal probability</span>. For example, probability based solely on the teen variable is a marginal probability.</p>
                    <img src="../img/statistics-for-data-science/probability-27.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The probability of outcomes for two or more variables or processes is called a <span class="badge rounded-pill bg-secondary">joint probability</span>. For example, the probability that a child went to college when their parents did not.</p>
                    <img src="../img/statistics-for-data-science/probability-26.PNG" class="mx-auto d-block" alt="Probability">
                    <h2 class="h4">General multiplication rule</h2>
                    <p>Here we provide the General Multiplication Rule for events that might not be independent. This <span class="badge rounded-pill bg-secondary">General Multiplication Rule</span> is simply a rearrangement of the conditional probability equation.</p>
                    <img src="../img/statistics-for-data-science/probability-28.PNG" class="mx-auto d-block" alt="Probability">
                    <p>When events A and B are independent, the probability of event A is not impacted by the occurrence of event B and vice versa, so the following applies (see <a href="#multiplication-rule">Multiplication rule for independent processes</a>):</p>
                    <img src="../img/statistics-for-data-science/probability-29.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-30.PNG" class="mx-auto d-block" alt="Probability">
                    <h3 class="h5">Sum of conditional probabilities</h3>
                    <p>Let A<sub>1</sub>, ..., A<sub>k</sub> represent all the disjoint outcomes for a variable or process A. Then if B is an event, possibly for another variable or process, we have:</p>
                    <img src="../img/statistics-for-data-science/probability-31.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The rule for complements also holds when an event and its complement are conditioned on the same information:</p>
                    <img src="../img/statistics-for-data-science/probability-32.PNG" class="mx-auto d-block" alt="Probability">
                    <p><em>Example 1:</em> In your sock drawer, you have 4 blue, 5 grey, and 3 black socks. Half asleep one morning, you grab 2 socks at random and put them on. Find the probability you end up wearing: 1 - 2 blue socks; 2 - no grey socks; 3 - at least 1 black sock; 4 - a green sock; 5 - matching socks.<img src="../img/statistics-for-data-science/probability-33.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <h2 class="h4">Tree diagrams</h2>
                    <p><em>Example 2:</em><img src="../img/statistics-for-data-science/probability-4.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-7.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <h2 class="h4">Bayes' Theorem</h2>
                    <img src="../img/statistics-for-data-science/probability-34.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-35.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-36.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-37.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-38.PNG" class="mx-auto d-block" alt="Probability">
                    <p><em>Example 3:</em> Jose visits campus every Thursday evening. However, some days the parking garage is full, often due to college events. There are academic events on 35% of evenings, sporting events on 20% of evenings, and no events on 45% of evenings. When there is an academic event, the garage fills up about 25% of the time, and it fills up 70% of evenings with sporting events. On evenings when there are no events, it only fills up about 5% of the time. If Jose comes to campus and finds the garage full, what is the probability that there is a sporting event?<br>
                        Using a tree diagram:<img src="../img/statistics-for-data-science/probability-10.PNG" class="mx-auto d-block" alt="Probability">Using Bayes' Theorem:<img src="../img/statistics-for-data-science/probability-15.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <p><em>Example 4:</em><img src="../img/statistics-for-data-science/probability-41.PNG" class="mx-auto d-block" alt="Probability">Using Bayes' Theorem:<img src="../img/statistics-for-data-science/probability-43.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <p><em>Example 5:</em><img src="../img/statistics-for-data-science/probability-45.PNG" class="mx-auto d-block" alt="Probability">*This is a conditional probability; we want P(Bowl 1 | Vanilla), but it is not obvious how to compute it. If I asked a different question - the probability of a vanilla cookie given bowl 1 - it would be easy (P(Vanilla | Bowl 1) = 3/4). Sadly, P(A | B) is not the same as P(B | A), but there is a way to get from one to the other: Bayes's theorem.</p>
                    <p><em>Example 6:</em><img src="../img/statistics-for-data-science/probability-46.PNG" class="mx-auto d-block" alt="Probability"><img src="../img/statistics-for-data-science/probability-47.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <h2 class="h4">The diachronic interpretation</h2>
                    <p>There is another way to think of Bayes' theorem: it gives us a way to update the probability of a hypothesis, H, in light of some body of data, D. This way of thinking about Bayes' theorem is called the <span class="badge rounded-pill bg-secondary">diachronic interpretation</span>. "Diachronic" means that something is happening over time; in this case the probability of the hypotheses changes, over time, as we see new data.</p>
                    <p>Rewriting Bayes' theorem with H and D yields:</p>
                    <img src="../img/statistics-for-data-science/probability-48.PNG" class="mx-auto d-block" alt="Probability">
                    <p>In this interpretation, each term has a name:</p>
                    <ul>
                        <li>P(H) is the probability of the hypothesis before we see the data, called the prior probability, or just <span class="badge rounded-pill bg-secondary">prior</span>.</li>
                        <li>P(H | D) is what we want to compute, the probability of the hypothesis after we see the data, called the <span class="badge rounded-pill bg-secondary">posterior</span>.</li>
                        <li>P(D | H) is the probability of the data under the hypothesis, called the <span class="badge rounded-pill bg-secondary">likelihood</span>.</li>
                        <li>P(D) is the probability of the data under any hypothesis, called the <span class="badge rounded-pill bg-secondary">normalizing constant</span>.</li>
                    </ul>
                    <p><em>Example 7:</em><img src="../img/statistics-for-data-science/probability-49.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <h2 class="h4">Expectation</h2>
                    <p>Two books are assigned for a statistics class: a textbook and its corresponding study guide. The university bookstore determined 20% of enrolled students do not buy either book, 55% buy the textbook only, and 25% buy both books, and these percentages are relatively constant from one term to another. The textbook costs $137 and the study guide $33.</p>
                    <p>We call a variable or process with a numerical outcome a <span class="badge rounded-pill bg-secondary">random variable</span>, and we usually represent this random variable with a capital letter such as X, Y , or Z. The amount of money a single student will spend on her statistics books is a random variable, and we represent it by X. The possible outcomes of X are labeled with a corresponding lower case letter x and subscripts. For example, we write x<sub>1</sub> = $0, x<sub>2</sub> = $137, and x<sub>3</sub> = $170, which occur with probabilities 0.20, 0.55, and 0.25:</p>
                    <img src="../img/statistics-for-data-science/probability-16.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The <span class="badge rounded-pill bg-secondary">expected value</span> of a random variable is computed by adding each outcome weighted by its probability (E(X) = 0 &times; P(X = 0) + 137 &times; P(X = 137) + 170 &times; P(X = 170) = 0 &times; 0.20 + 137 &times; 0.55 + 170 &times; 0.25 = 117.85). </p>
                    <h3 class="h5">Expected value of a discrete random variable</h3>
                    <p>If X takes outcomes x<sub>1</sub>, ..., x<sub>k</sub> with probabilities P(X = x<sub>1</sub>), ..., P(X = x<sub>k</sub>), the expected value of X is the sum of each outcome multiplied by its corresponding probability:</p>
                    <img src="../img/statistics-for-data-science/probability-42.PNG" class="mx-auto d-block" alt="Probability">
                    <p>The expected value for a random variable represents the <span class="badge rounded-pill bg-secondary">average outcome</span>. For example, E(X) = 117.85 represents the average amount the bookstore expects to make from a single student, which we could also write as &mu; = 117.85.</p>
                    <h2 class="h4">Variability in random variables</h2>
                    <p>The <span class="badge rounded-pill bg-secondary">variance</span> and <span class="badge rounded-pill bg-secondary">standard deviation</span> can be used to describe the variability of a random variable. In the case of a random variable, we again compute squared deviations. However, we take their sum weighted by their corresponding probabilities, just like we did for the expectation.</p>
                    <h3 class="h5">General variance formula</h3>
                    <p>If X takes outcomes x<sub>1</sub>, ..., x<sub>k</sub> with probabilities P(X = x<sub>1</sub>), ..., P(X = x<sub>k</sub>) and expected value &mu; = E(X), then the variance of X, denoted by Var(X) or the symbol &sigma;<sup>2</sup>, is<img src="../img/statistics-for-data-science/probability-40.PNG" class="mx-auto d-block" alt="Probability"></p>
                    <p>The standard deviation of X, labeled &sigma;, is the square root of the variance.</p>
                    <p><em>Example 4:</em><img src="../img/statistics-for-data-science/probability-39.PNG" class="mx-auto d-block" alt="Probability"></p>
                </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingThree">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="true" aria-controls="collapseThree">Distribution of Random Variables</button>
            </h2>
            <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingFour">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseFour" aria-expanded="true" aria-controls="collapseFour">Introduction to Statistical Inference</button>
            </h2>
            <div id="collapseFour" class="accordion-collapse collapse" aria-labelledby="headingFour" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingFive">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseFive" aria-expanded="true" aria-controls="collapseFive">Hypothesis Testing</button>
            </h2>
            <div id="collapseFive" class="accordion-collapse collapse" aria-labelledby="headingFive" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingSix">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSix" aria-expanded="true" aria-controls="collapseSix">ANOVA, Goodness of Fit, and Bootstrapping</button>
            </h2>
            <div id="collapseSix" class="accordion-collapse collapse" aria-labelledby="headingSix" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingSeven">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSeven" aria-expanded="true" aria-controls="collapseSeven">Linear Regression</button>
            </h2>
            <div id="collapseSeven" class="accordion-collapse collapse" aria-labelledby="headingSeven" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingEight">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseEight" aria-expanded="true" aria-controls="collapseEight">Logistic Regression</button>
            </h2>
            <div id="collapseEight" class="accordion-collapse collapse" aria-labelledby="headingEight" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingNine">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseNine" aria-expanded="true" aria-controls="collapseNine">Time Series</button>
            </h2>
            <div id="collapseNine" class="accordion-collapse collapse" aria-labelledby="headingNine" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingTen">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseTen" aria-expanded="true" aria-controls="collapseTen">Introduction to Causal Inference Part 1</button>
            </h2>
            <div id="collapseTen" class="accordion-collapse collapse" aria-labelledby="headingTen" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingEleven">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseEleven" aria-expanded="true" aria-controls="collapseEleven">Introduction to Causal Inference Part 2</button>
            </h2>
            <div id="collapseEleven" class="accordion-collapse collapse" aria-labelledby="headingEleven" data-bs-parent="#accordionExample">
                <div class="accordion-body"> </div>
            </div>
        </div>
    </div>
</div>
<script src="../js/"></script> 
<script src="../js/bootstrap.min.js"></script>
</body>
</html>