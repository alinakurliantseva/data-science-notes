<!DOCTYPE html>
<html lang="en">
<head>
<title>Using Python II: Clean, Predict and Inform (School of Continuing Studies, University of Toronto)</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="shortcut icon" href="../img/favicon.ico">
<link rel="stylesheet" href="../css/bootstrap.min.css">
</head>
<body>
<div class="container">
    <h1 class="text-center mt-5 mb-5">Using Python II: Clean, Predict and Inform</h1>
    <p class="text-end mb-5"><em>School of Continuing Studies, University of Toronto</em></p>
    <div class="accordion" id="accordionExample">
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingOne">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">Data Cleaning</button>
            </h2>
            <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <p>Common data issues:</p>
                    <ul>
                        <li>Inconsistent format (416-123-4567 vs. 4161234567)</li>
                        <li>Incorrectly captured data (Toronot vs. Toronto)</li>
                        <li>Concatenated data (TorontoON, A1A1A1ON)</li>
                        <li>Irrelevant data (capturing age, but not birthdate)</li>
                        <li>False data (fake birthdate, fake name)</li>
                        <li>Incomplete data (John S. vs. John Smith)</li>
                        <li>Missing data</li>
                        <li>Wrong data type</li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Variable identification</span> refers to understanding what is meant by each variable in your data set (population (of a country or city? sample?), abbreviations, acronyms). Build a <span class="badge rounded-pill bg-secondary">data dictionary</span> for your data set to ensure all stakeholders, and team members, are aligned.</p>
                    <p>Data should be organized such that it can be interpreted by statistical software:</p>
                    <ul>
                        <li>Each variable should have its own column</li>
                        <li>Each observation should have its own row</li>
                        <li>Each value should have its own cell</li>
                        <li>Multiple tables should be joined by a column</li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Univariate asnalysis</span> refers to understanding the distribution of each variable (Does the range make sense? Does the distribution make sense? Should there be negative values? Zeros? N/As? Is the data coded correctly?). Summary statistics can be used to review individual variables: mean, median, mode, range, standard deviation, variance. In addition, visualizing data helps. For distributions, consider histograms, and for time series – line charts.</p>
                    <p>A <span class="badge rounded-pill bg-secondary">normal distribution</span> follows the central limit theory which states that some independent factors influence a particular characteristic. When these independent factors contribute to the characteristic individually, their normalized sum tends to result in a Gaussian distribution (in other words, a normal distribution).</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/normal-distribution.PNG" class="mx-auto d-block" alt="Normal distribution">
                    <p><span class="badge rounded-pill bg-secondary">Bivariate analysis</span> refers to understanding variables in pairs. This can be done through the use of a scatter plot to identify correlations.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/bivariate-analysis.PNG" class="mx-auto d-block" alt="Bivariate analysis">
                    <p><span class="badge rounded-pill bg-secondary">Missing data</span> refers to data points not available for a certain observation. In Python, they're typically denoted with NaN. This occurs when collection efforts are incomplete (e.g., a survey participants fills out 48/50 questions).</p>
                    <p>Missing data patterns:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">MCAR: Missing Completely at Random</span>
                            <ul>
                                <li>No pattern to define missing data</li>
                                <li>Could occur because of technical errors / challenges, errors in data collection, or survey participants omitting information</li>
                                <li>If an analysis is done using a person's postal code at work and home to determine commute distance, and someone did not know a work postal code, but no other relevant information has been collected (e.g., length of time at employer), this would be MCAR</li>
                                <li>MCAR rarely results in biased outputs; therefore, it can be corrected by omitting incomplete records from the sample</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">MAR: Missing at Random</span>
                            <ul>
                                <li>A pattern exists (i.e., the probability of an observation missing can be explained by the data available)</li>
                                <li>It is impossible to prove that data is MAR, however one can demonstrate the likelihood of data missing based on individual responses (e.g., if individuals are less likely to remember, or a condition would trigger them not to respond)</li>
                                <li>If we ask individuals in a survey to tell us the genre of the last movie they went to see and how long ago they went to the movies, there is a probability that respondents who have not been at the movies for over 6 months will not remember the genre of the last movie seen</li>
                                <li>If data is MAR, it cannot be ignored</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">MNAR: Missing Not at Random</span>
                            <ul>
                                <li>Data missing not at random is missing data with a pattern to the likelihood that a data element is missing that depends on the missing element</li>
                                <li>If asking a person how many crimes they committed but got away with in the last year, they may choose not to respond due to the nature of the question</li>
                                <li>Data MNAR poses serious problems with the analysis, as the relevant data is missing</li>
                            </ul>
                        </li>
                    </ul>
                    <p>Techniques for missing data:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Drop observation</span>
                            <ul>
                                <li>Used for MCAR data</li>
                                <li>Drop observations which have missing data</li>
                                <li>Count the number of NaNs and determine if removing the observations would cause a significant impact to the sample size</li>
                                <li>Rule of thumb: less than 10% of observations can be removed</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">Mean/median substitution</span>
                            <ul>
                                <li>Used for MCAR data</li>
                                <li>Substitute missing values with the mean of the field</li>
                                <li>Be mindful of data stratification (e.g., age groups, postal code, etc.); use the groupby() function to segregate different observation groups</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">Modeling techniques</span>
                            <ul>
                                <li>Techniques depend on developing a model for the missing observation based on the remaining data</li>
                            </ul>
                        </li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Data cleaning</span> (cheat sheet):</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Categorical data</span>:
                            <ul>
                                <li>Consistency in formatting (e.g., if you captured data about where someone lives and it’s in various formats like US, USA, U.S.A., you would need to create a consistent structure) - dictionary / str.contains() / str.replace()</li>
                                <li>Pulling information from identifiers (e.g., let’s say you have product identifiers like ON879X and BC7687X - if the first 2 letters of the identifier reflect the province of origin, you should spike those out so you can use them for analysis) - str.contains()</li>
                                <li>Filling in missing values - "Other" / mode</li>
                                <li>Dropping missing values (if a column or row has too many missing values, drop it) - drop() + a threshold parameter for the minimum number of NON-missing values a row / column should have before it is dropped</li>
                                <li>Create broader categories for detailed breakdowns (if you have many small groupings, consider putting them in an "Other" category)</li>
                                <li>Names (if you have a full name for people, split by first and last name) - split() / rsplit()</li>
                            </ul>
                        </li>
                        <li><span class="badge rounded-pill bg-secondary">Numerical data</span>:
                            <ul>
                                <li>Check for negatives where negative numbers don’t make sense (e.g., negative nutritional values, negative salary, negative expenses)</li>
                                <li>Check for 0s where 0s don’t make sense</li>
                                <li>Check the maximum and whether it makes sense (e.g., age = 150 does not make sense)</li>
                                <li>Use a boxplot to check outliers</li>
                                <li>Check for normality using a histogram or distribution plot</li>
                                <li>Check for missing values and impute them based on mean or median (median when the distribution is not normal); remember to stratify the data before imputing values, if possible, for example, by gender or another demographic data point - fillna() + of groupby() + transform(); if you have more than 10% missing values, consider deleting the column</li>
                                <li>Check all descriptive statistics (standard deviation, mean, min, max, variance, range) to see if they make sense based on the problem - describe(); if your data has a large variance or standard deviation, perhaps, it makes sense to stratify further (e.g., if you are looking for information on first time home buyers and your age has a standard deviation of 10 and the mean is 35, you may be looking at multiple markets of buyers rather than first time home buyers - so you may want to look at the age range of 20-35 separately, then 36+ separately (presumably, these are upgrading buyers rather than first time))</li>
                            </ul>
                        </li>
                    </ul>
                    <p><em>Example 1:</em> Data cleaning.<img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning.PNG" class="mx-auto d-block" alt="Data cleaning"><span class="badge rounded-pill bg-secondary">Dealing with wrong data type</span>: There are a few functions which can convert a column of data to a new data type. For example, to convert an entire data frame to a new data type, you could use astype() like this: <span class="badge rounded-pill bg-secondary">df = df.astype(str)</span>. You could also use this function in a specific column, for example: <span class="badge rounded-pill bg-secondary">df['column'] = df.column.astype(int)</span>. One of the most common data issues is a column which SHOULD be numeric, but is not. In addition to the above method, we could also use the pandas function <span class="badge rounded-pill bg-secondary">to_numeric()</span> which allows us to, at the same time, convert a column to a numeric data type and deal with any errors. Why do errors happen? In some cases, you may have a word in the place of a number for a certain entry. If this is the case, Python will automatically capture that entire column as "object". With the to_numeric() function, we can convert the column to numeric format and "coerce" errors - this simply means that we convert any non-numeric data to a Null value (missing value). We can then replace the missing value.<img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-wrong-data-type.PNG" class="mx-auto d-block" alt="Dealing with wrong data type"><span class="badge rounded-pill bg-secondary">Dealing with inconsistent data</span>: Sometimes, data can be stored inconsistently. For example, in many free-form fields that capture customer data, if the format of how the data should be captured is not defined, people may enter it differently. In our data set, we can identify inconsistently captured data using the <span class="badge rounded-pill bg-secondary">unique()</span> function, or by looking for patterns. For this example, I will keep it simple. If we pull out unique phone numbers, we will see that we have four patterns: XXX-XXX-XXXX, XXXXXXXXX, XXX-XXXXXXX, XXXXXX-XXXX. Unfortunately, most data cleaning is quite manual (even with Python) so it will take some manual effort to complete. For this purpose, we are going to use RegularExpressions (the library is called re). This library allows us to work with text data quite easily. What we are going to do is define our patterns using the <span class="badge rounded-pill bg-secondary">re.compile()</span> function, then for each entry, we will look for these patterns and replace them with the pattern we want, which is: XXX-XXX-XXXX. To do this, we will use simply the <span class="badge rounded-pill bg-secondary">join()</span> function with some digit locations. The best way to apply a fix like this is by defining a custom function, and then applying it to a column (this is also a good way to automate data cleaning).<img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-inconsistent-data.PNG" class="mx-auto d-block" alt="Dealing with inconsistent data"><span class="badge rounded-pill bg-secondary">Dealing with data mistakes</span>: Sometimes we may have captured data using a free-form method and we can come across issues like spelling mistakes. As before, it will be a manual effort to identify such issues and I like to use the <span class="badge rounded-pill bg-secondary">unique()</span> function so I can quickly identify things like spelling mistakes. In this example, we can see that we have multiple versions of Charlottetown, Ottawa, Toronto, and Winnipeg. The easiest way to deal with such data issues is to use the <span class="badge rounded-pill bg-secondary">str.replace()</span> method. For each inconsistency, you will essentially identify all instances of the wrongful spelling and replace them with the correct spelling. This function can be applied directly to a series (or column) in a pandas dataframe, so you don't need to use a "for loop".<img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-data-mistakes-a.PNG" class="mx-auto d-block" alt="Dealing with data mistakes"><img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-data-mistakes-b.PNG" class="mx-auto d-block" alt="Dealing with data mistakes"><span class="badge rounded-pill bg-secondary">Dealing with missing data</span>: We have missing data points in 3 columns: Income, Credit Limit, and Marital Status. When we are dealing with categorical data, such as Marital Status, we can simply create a new category called "Other" or we can select the mode (most frequently occuring value) and replace missing values with it. For numerical data, the simplest way is to replace missing values with the mean or median. You can do this as the blanket mean / median of the column, or you can organize by some category - for example, group by Marital Status and replace the mean for single vs. divorced vs. married people.<img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-missing-data-a.PNG" class="mx-auto d-block" alt="Dealing with missing data"><img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-missing-data-b.PNG" class="mx-auto d-block" alt="Dealing with missing data"><span class="badge rounded-pill bg-secondary">Dealing with concatenated data</span>: Our "Name" column seems to capture first, last, and in some cases, middle names. This may be okay, but in some instances we may be interested in splitting up the names. Since this is text data, we can use some string methods to do so. We can use <span class="badge rounded-pill bg-secondary">str.split()</span> or <span class="badge rounded-pill bg-secondary">str.rsplit()</span> for this: str.split() will split a string starting on the left hand side, while rsplit() will do so starting on the right hand side. The "n" parameter in this function tells it how many times to split (once, twice, and so on). In our case, we only need to split once, and we will use rsplit(). Why? Bacause in cases where we have middle names, we are going to record these as part of the first name. You need to watch out for and determine how to treat common name issues, like hyphenated names, middle initials, middle names, 2 last names, and so on.<img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-concatenated-data.PNG" class="mx-auto d-block" alt="Dealing with missing data"><span class="badge rounded-pill bg-secondary">Dealing with irrelevant data</span>: We have information about people's birthdates in this data set, but this isn't very useful if we don't have the age. Lucky for us, we can calculate age using the birthdate variable. We first have to convert the Birth Date column to a datetime value, and then check for issues (which we will fix manually). Once it's in the correct format, we can convert to Age.<img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-irrelevant-data-a.PNG" class="mx-auto d-block" alt="Dealing with irrelevant data"><img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-irrelevant-data-b.PNG" class="mx-auto d-block" alt="Dealing with irrelevant data"><img src="../img/using-python-ii-clean-predict-and-inform/dealing-with-irrelevant-data-c.PNG" class="mx-auto d-block" alt="Dealing with irrelevant data"><span class="badge rounded-pill bg-secondary">Creating categories of data based on text</span>:<img src="../img/using-python-ii-clean-predict-and-inform/creating-categories-of-data-based-on-text-a.PNG" class="mx-auto d-block" alt="Creating categories of data based on text"><img src="../img/using-python-ii-clean-predict-and-inform/creating-categories-of-data-based-on-text-b.PNG" class="mx-auto d-block" alt="Creating categories of data based on text"><img src="../img/using-python-ii-clean-predict-and-inform/creating-categories-of-data-based-on-text-c.PNG" class="mx-auto d-block" alt="Creating categories of data based on text"><img src="../img/using-python-ii-clean-predict-and-inform/creating-categories-of-data-based-on-text-d.PNG" class="mx-auto d-block" alt="Creating categories of data based on text"></p>
                    <p><em>Example 2:</em><br>
                        Identify the errors in province names.<img src="../img/using-python-ii-clean-predict-and-inform/practice-questions-1.PNG" class="mx-auto d-block" alt="Practice questions">Create a dictionary object to change the wrongfully captured province names to the following format: ON, MB, QB, etc.<img src="../img/using-python-ii-clean-predict-and-inform/practice-questions-2.PNG" class="mx-auto d-block" alt="Practice questions">Apply the dictionary to the "province" column.<img src="../img/using-python-ii-clean-predict-and-inform/practice-questions-3.PNG" class="mx-auto d-block" alt="Practice questions">Fill in missing values in the "province" column with "Other".<img src="../img/using-python-ii-clean-predict-and-inform/practice-questions-4.PNG" class="mx-auto d-block" alt="Practice questions">Convert the "net_worth" column to a numeric data type. Python doesn't recognize currency so you will need to remove the "$" and "," symbols from each value.<img src="../img/using-python-ii-clean-predict-and-inform/practice-questions-5.PNG" class="mx-auto d-block" alt="Practice questions"></p>
                    <p><em>Example 3:</em> Missing data.<img src="../img/using-python-ii-clean-predict-and-inform/missing-data.PNG" class="mx-auto d-block" alt="Missing data"></p>
                    <p><em>Example 4:</em> Assignment 1 <em>(selected examples)</em>.<br>
                        Create a new "Type of Cereal" column in your data frame by copying the "name" column. Write a function to replace the names of the cereal in your new column with one of these categories: Bran, Wheat, Fiber, Protein, Crunch, Corn, Nut, Rice, and Other.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-1.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Identify the negative values in the data set and replace them with the median value for that column.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-2.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Standardize the "weight" column to 1.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-3.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Create a new column to categorize cereals as "healthy" vs. "unhealthy".<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-4.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Based on your newly prepared data set, identify what % of cereals that each manufacturer produces are healthy.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-5.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Calculate the average, minimum, and maximum ratings for healthy vs. unhealthy cereals.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-6.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Calculate the average, minimum, and maximum ratings for each type of cereal: Bran, Wheat, Fiber, Protein, Crunch, Corn, Nut, Rice, and Other.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-7.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Create a stacked bar chart that shows how many of each type of cereal each manufacturer produces.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-8.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Create a 3-dimensional scatterplot that shows the relationship between rating and calories; the 3-rd dimension should be reflected in the color of the dots and should highlight whether the cereal is categorized as healthy or unhealthy.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-9.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration">Which shelf has the most healthy cereals?<img src="../img/using-python-ii-clean-predict-and-inform/assignment-1-10.PNG" class="mx-auto d-block" alt="Assignment 1 - data cleaning and exploration"></p>
                </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingTwo">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="true" aria-controls="collapseTwo">Exploratory Analysis and Working with Time Series Data</button>
            </h2>
            <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <p>Once data is cleaned and missing values are addressed, we want to explore the data to understand the data set in advance of preparing a model. This includes understanding relationships between variables, data stratification, and using summary statistics to inform hypotheses.</p>
                    <p><span class="badge rounded-pill bg-secondary">Univariate analysis</span>:</p>
                    <ul>
                        <li>Categorical data:
                            <ul>
                                <li>Counts of categories - how many observations in each?</li>
                                <li>What % of each category is represented in the data set?</li>
                                <li>This information will help structure the bivariate analysis</li>
                            </ul>
                        </li>
                        <li>Continuous data:
                            <ul>
                                <li>Mean, median, standard deviation, variance, min, max, range</li>
                                <li>Understand spread and distribution of data using histograms</li>
                                <li>View outliers using boxplots</li>
                            </ul>
                        </li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Bivariate analysis</span>:</p>
                    <ul>
                        <li>Categorical - continuous data:
                            <ul>
                                <li>Group by category and calculate mean, median, standard deviation, variance, min, max, range by category</li>
                            </ul>
                        </li>
                        <li>Categorical - categorical data:
                            <ul>
                                <li>Group by category and calculate count of secondary category</li>
                            </ul>
                        </li>
                        <li>Continuous - continuous data:
                            <ul>
                                <li>Correlation coefficients</li>
                                <li>Scatterplots to assess relationship</li>
                            </ul>
                        </li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Time series patterns</span>:</p>
                    <p>A <span class="badge rounded-pill bg-secondary">trend</span> exists when there is a long-term increase or decrease in the data. It does not have to be linear.</p>
                    <p><span class="badge rounded-pill bg-secondary">Seasonality</span> occurs when a time series is affected by seasonal factors such as the time of the year or the day of the week or other calendar period (i.e., comparing only December across all years). Seasonality is always of a fixed and known period.</p>
                    <p><span class="badge rounded-pill bg-secondary">Cycles</span> occur when the data exhibit rises and falls that are not of a fixed period. These fluctuations are usually due to economic conditions and are often related to the business cycle. Cycles are patterns of repeated increase and decrease of varying period.</p>
                    <p>Seasonal patterns have a fixed and known length, while cyclic patterns have variable and unknown length. The average length of a cycle is usually longer than that of seasonality, and the magnitude of cyclic variation is usually more variable than that of seasonal variation.</p>
                    <p><span class="badge rounded-pill bg-secondary">Exploratory time series analysis</span>:</p>
                    <p><span class="badge rounded-pill bg-secondary">Step 1</span>: Graph time series data to identify whether trends, cycles or seasonality (or a combination of these) exist. Use the <span class="badge rounded-pill bg-secondary">time plot</span> functionality from Pandas to identify trends. Time plots are used to plot observation values against the time of observations and joined by straight lines.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/exploratory-time-series-analysis-step-1.PNG" class="mx-auto d-block" alt="Exploratory time series analysis - step 1">
                    <p>Most time series methods make an assumption of <span class="badge rounded-pill bg-secondary">stationarity</span> – meaning that a time series' statistical properties (mean, variance, growth rate) do not vary over time. The data is normal. This is also sometimes called <span class="badge rounded-pill bg-secondary">white noise</span>.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/stationarity-and-non-stationarity-time-series.PNG" class="mx-auto d-block" alt="Stationarity and non-stationarity time series">
                    <p>To analyze white noise data:</p>
                    <ul>
                        <li>Plot the data on a graph over time (line graph)</li>
                        <li>Use the series summary to calculate basic statistics</li>
                        <li>Calculate basic statistics for a smaller sample size</li>
                        <li>Use a lag plot to assess stability</li>
                        <li>Use an autocorrelation plot to detect portions of the time series which are not stationary</li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Step 2</span>: Create a <span class="badge rounded-pill bg-secondary">seasonal plot</span> using Pandas. Seasonal plots are similar to time series, but they plot data against individual seasons. That is to say the same data is shown using a different time horizon or unit of time, creating simultaneous views of different time slices.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/exploratory-time-series-analysis-step-2.PNG" class="mx-auto d-block" alt="Exploratory time series analysis - step 2">
                    <p><span class="badge rounded-pill bg-secondary">Step 3</span>: Create a <span class="badge rounded-pill bg-secondary">lag plot</span> to compare time series data points against themselves with a fixed delay or sequence shift. This would help identify seasonality at a specific period of time.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/exploratory-time-series-analysis-step-3.PNG" class="mx-auto d-block" alt="Exploratory time series analysis - step 3"><img src="../img/using-python-ii-clean-predict-and-inform/lag-plot.PNG" class="mx-auto d-block" alt="Lag plot">
                    <p>Autocorrelation plot for multiple lags:</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/autocorrelation-plot-for-multiple-lags.PNG" class="mx-auto d-block" alt="Autocorrelation plot for multiple lags">
                    <p><span class="badge rounded-pill bg-secondary">Forecasting</span> is about predicting future events as accurately as possible. Predictions (in the form of a time series) are an important aid for effective and efficient planning. Often a key step is knowing when something can be forecast accurately, and when forecasts will be no better than random chance. Good forecasts capture patterns / relationships in the historical data, without replicating past events that are unlikely to reoccur.</p>
                    <p><span class="badge rounded-pill bg-secondary">Cross-sectional forecasting</span> is an observational analysis from a population, or a representative subset, at a specific point in time. In contrast, <span class="badge rounded-pill bg-secondary">time series forecasting</span> uses only information on the variable(s) to be forecast and makes no attempt to discover additional factors which affect its behavior.</p>
                    <p>Prediction dependencies:</p>
                    <ul>
                        <li>how well we understand the factors contributing to the quantity</li>
                        <li>how much data is available</li>
                        <li>how past forecasts can affect future forecasts</li>
                    </ul>
                    <p>Forecasting situations vary widely and methods can be very simple such as using the most recent observation as a forecast. Forecasting can be applied when two conditions are satisfied: historical data is available; it is reasonable to assume that some aspects of the past patterns will continue into the future.</p>
                    <p>The <span class="badge rounded-pill bg-secondary">average method</span> simply takes the average of historical observations and sets the future values as this average. A <span class="badge rounded-pill bg-secondary">weighted average</span> can also be used, by setting a predicted value based on the average of the last n observations.</p>
                    <p>The <span class="badge rounded-pill bg-secondary">naive method</span> simply sets all predicted values as the last observed value. This is often used in economic and financial time series forecasting. This only works for time series data.</p>
                    <p>The <span class="badge rounded-pill bg-secondary">seasonal naive method</span> sets all predicted values as the last observed value from the same season.</p>
                    <p>The <span class="badge rounded-pill bg-secondary">drift method</span> is a variation on naive where we extrapolate the trend by drawing a line through the first and last observations. The amount of change over time (called the drift) is set to be the average change seen in the historical data. This is equivalent to drawing a line between the first and last observation, and extrapolating it into the future. Unlike prior methods, this is an estimation of growth, rather than a future value. The growth estimate can then be applied to the last known value to obtain a forecast projection.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/drift-method.PNG" class="mx-auto d-block" alt="Drift method">
                    <p>The purpose of adjustments and transformations are essentially cleaning up or preparing data, reducing noise, or correcting the context:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Calendar adjustments</span> refer to variation seen in seasonal data due to simple calendar effects (i.e., months don't have the same number of days). In such cases, it is usually much easier to remove the variation before fitting a forecasting model (i.e., re-calculate time series with a consistent time interval between measures).</li>
                        <li><span class="badge rounded-pill bg-secondary">Population adjustments</span> - any data that are affected by population changes can be adjusted to give per-capita data. That is, consider the data per person (or per thousand people, or per million people) rather than the total. For most data that are affected by population changes, it is best to use per-capita data rather than the totals.</li>
                        <li><span class="badge rounded-pill bg-secondary">Inflation adjustments</span> - data that are affected by the value of money are best adjusted before modeling. For this reason, financial time series are usually adjusted so all values are stated in dollar values from a particular year or known point of reference.</li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Exploratory data analysis</span> (checklist):</p>
                    <ul>
                        <li>Use df.info() to check data types and issues with missing values</li>
                        <li>Clean data</li>
                        <li>Use df.describe() to understand key metrics for all numeric columns. This can be used to quickly understand ranges, standard deviation, mean, min, max and quartile data (indicator of skew)</li>
                        <li>Conduct univariate analysis (explore each variable by itself) for numeric variables:
                            <ul>
                                <li>Mean</li>
                                <li>Median</li>
                                <li>Min</li>
                                <li>Max</li>
                                <li>Range</li>
                                <li>Count</li>
                                <li>Sum (if appropriate)</li>
                                <li>Plot histogram to look at the distribution</li>
                                <li>Plot boxplot to identify outliers (remove outliers)</li>
                                <li>Determine if data would be more meaningful if split into further categories / buckets</li>
                            </ul>
                        </li>
                        <li>Conduct univariate analysis for categorical variables:
                            <ul>
                                <li>Mode</li>
                                <li>Count by category (use groupby() for this)</li>
                                <li>% by category</li>
                                <li>Plot bar charts to view category split</li>
                                <li>Determine if sample is representative or if adjustments are needed</li>
                                <li>Determine if smaller categories can be grouped in one (e.g., "other")</li>
                            </ul>
                        </li>
                        <li>Conduct bivariate analysis for all numeric - numeric column combinations:
                            <ul>
                                <li>Calculate correlation coefficients (df.corr() is useful)</li>
                                <li>Plot scatterplots between numerical variables to check visibly for correlation or pattern</li>
                            </ul>
                        </li>
                        <li>Conduct bivariate analysis for all numeric - categorical column combinations:
                            <ul>
                                <li>Group by categorical variables and calculate corresponding stats for numeric variables (mean, median, mode, max, min) - e.g., group by gender and calculate income stats - you can use aggregate() for this</li>
                            </ul>
                        </li>
                        <li>Conduct bivariate analysis for categorical - categorical column combinations:
                            <ul>
                                <li>Group by categorical variables and count other categories - e.g., men vs. women in survived vs. not (Titanic)</li>
                            </ul>
                        </li>
                        <li>Group by multiple categorical variables and calculate numeric variables (e.g., group by gender and country of origin to calculate avg income)</li>
                        <li>List all leads or major findings, and build models (regression, classification) to validate</li>
                    </ul>
                    <p><em>Example 1:</em> Data exploration.<img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-1.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-2.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-3.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-4.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-5.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-6.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-7.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-8.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-9.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-10.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-11.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-12.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-13.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-14.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-15.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-16.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-17.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-18.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-19.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-20.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-21.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-22.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-23.PNG" class="mx-auto d-block" alt="Data exploration"><img src="../img/using-python-ii-clean-predict-and-inform/data-exploration-24.PNG" class="mx-auto d-block" alt="Data exploration"></p>
                    <p><em>Example 2:</em> Check a string and return any values that are in the string.<img src="../img/using-python-ii-clean-predict-and-inform/check-a-string.PNG" class="mx-auto d-block" alt="Check a string"></p>
                    <p><em>Example 3:</em> Time series analysis.<img src="../img/using-python-ii-clean-predict-and-inform/time-series-1.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-2.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-3.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-4.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-5.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-6.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-7.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-8.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-9.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-10.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-11.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-12.PNG" class="mx-auto d-block" alt="Time series"><img src="../img/using-python-ii-clean-predict-and-inform/time-series-13.PNG" class="mx-auto d-block" alt="Time series"></p>
                    <p><em>Example 4:</em> Assignment 2 <em>(selected examples)</em>.<br>
                        Download the adjusted close prices for FB, MMM, IBM, and AMZN for the last 60 months.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-1.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis">Resample the data to get prices for the end of the business month. Select the Adjusted Close for each stock.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-2.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis">Use the pandas autocorrelation_plot() function to plot the autocorrelation of the adjusted month-end close prices for each of the stocks.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-3a.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-3b.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-3c.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-3d.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis">Calculate the monthly returns for each stock using the shift() function. Use pandas autotocorrelation_plot() to plot the autocorrelation of the monthly returns.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-4a.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-4b.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-4c.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-4d.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis">Combine all 4 time series (returns) into a single DataFrame, visualize the correlation between the returns of all pairs of stocks using the scatter_matrix() function from pandas.plotting.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-2-5.PNG" class="mx-auto d-block" alt="Assignment 2 - time series analysis"></p>
                </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingThree">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="true" aria-controls="collapseThree">Introduction to Predictive Modeling and Model Building</button>
            </h2>
            <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <p>A <span class="badge rounded-pill bg-secondary">linear regression</span> model combines a series of parameters along with explanatory variables into a linear equation of the form:</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/linear-equation.PNG" class="mx-auto d-block" alt="Linear equation">
                    <p>The <span class="badge rounded-pill bg-secondary">error term</span> belongs in every regression model. Error term refers to the <span class="badge rounded-pill bg-secondary">residual value</span> (i.e., what is not explained by the equation).</p>
                    <p>The <span class="badge rounded-pill bg-secondary">econometric view of regression</span> is known as causal modelling, and sees the model development as an interaction between theory as expressed through mathematics and data through the statistics of regression: the mathematical model shows that the independent variables explain the behavior of the dependent variables (i.e., linear relationship); data is applied to the model to find the best fit. The objective of this approach is to find the model that best fits the data with as much of the variation as possible explained by the relationship (i.e., small error term).</p>
                    <p>The <span class="badge rounded-pill bg-secondary">black box method</span> is driven by algorithms that are highly automated. Techniques (e.g., ridge regression, lasso regression) do not leverage theory of causation but focus on managing tradeoffs between the number of explanatory variables used and amount of variation explained by the model.</p>
                    <p>The econometric approach requires more hands-on involvement, but allows for business knowledge to be considered when developing a theory. If the theory is correct, and independent variables are trustworthy in predicting dependent variable behavior, this model can be used for predictive and prescriptive analytics.</p>
                    <p>Some techniques in the black box approach are better for prediction (i.e., plugging in x-values to determine what could happen). If data to support a certain theory is unavailable, but a large amount of potentially relevant data is available, the black box method may be a better choice, as it can consider numerous models very quickly.</p>
                    <p>There are two packages which can be used for linear regression in Python: Statsmodels and Sklearn (called scikit-learn).</p>
                    <p><span class="badge rounded-pill bg-secondary">Interpreting regression results</span>:</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/interpreting-regression-results-1.PNG" class="mx-auto d-block" alt="Interpreting Regression Results"><img src="../img/using-python-ii-clean-predict-and-inform/interpreting-regression-results-2.PNG" class="mx-auto d-block" alt="Interpreting Regression Results">
                    <p><span class="badge rounded-pill bg-secondary">R-squared</span>: this articulates what percentage of the variability in Y is explained by the model. This value will always be between 0 and 1; if R-squared = 1, then the model perfectly explains variability in Y, while if R-squared = 0, there is no linear relationship.</p>
                    <p><span class="badge rounded-pill bg-secondary">std err</span>: this is the standard error of the coefficients. This measures the precision of the estimate of the coefficient.</p>
                    <p><span class="badge rounded-pill bg-secondary">P&gt;|t|</span>: to compute probability, it is assumed that the coefficient is 0 (there is no dependence). In other words, we assumed the coefficient is zero and under this assumption the probability to find the fitted value is P&gt;|t|. The small value of P means that assumption about the coefficient being zero is not reasonable and should be discarded. Attributes with the P-value (column P&gt;|t|) greater than 0.05 are not significant for this model. Attributes with values between 0 and 0.05 are statistically significant predictors of the response. In the given example, P&gt;|t| for the Tobacco is 0.007, it has value much smaller than 0.05 and we accept the fit of the regression line.</p>
                    <p>95% confidence interval: the two last columns - <span class="badge rounded-pill bg-secondary">[0.025&nbsp;&nbsp;&nbsp;0.975]</span> - give the confidence interval, that is, with 95% confidence the coefficient is between these limits.</p>
                    <p><span class="badge rounded-pill bg-secondary">F-statistic</span>: assessment of the overall effectiveness of the model (i.e., does the combination of independent variables have a statistically significant impact on the output, or would the result be the same without them there?).</p>
                    <p>Building the best model:</p>
                    <ul>
                        <li>Where possible, use theory to inform your model development</li>
                        <li>Maintain multiple data sets for developing, estimating, and testing</li>
                        <li>Where theory is weak, or nonspecific, use data to inform the model specification</li>
                        <li>When testing models, data permitting, over-specify them, which is to say, put in more variables than you need and test down rather than testing up</li>
                        <li>Resolve issues of collinearity, particularly as a result of multiple potential specifications with multivariate tests</li>
                    </ul>
                    <p><span class="badge rounded-pill bg-secondary">Feature engineering</span> is the process through which you create new variables to help make your model more accurate, useful or simpler (<span class="badge rounded-pill bg-secondary">features</span> are any variables which are important in your model).</p>
                    <p>Types of features:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Indicator</span> variables represent special groups, classes or periods of time. Represented as dummy or binary variables (i.e., 1 is when observation belongs to a group, 0 when it does not). For examples, marking groups belong to Canada vs. US, or special times of year like Boxing Day or not.</li>
                        <li><span class="badge rounded-pill bg-secondary">Interactions</span> are combinations of variables in the dataset. For example, calculating profit by subtracting cost from revenues. In Python, create a new column to calculate a new variable.</li>
                        <li>Feature <span class="badge rounded-pill bg-secondary">representations</span> make variables more useful. Examples include: combining sparse groups (e.g., small categories grouped as "other"), making variables more detailed (e.g., breaking down height by feet and inches), creating categorical mapping (e.g., grouping time of day by morning, afternoon or evening). These features are used for data that is difficult to model. In Python, you can use "where" statements to filter for certain values only, or you can use location indicators, or groupby().</li>
                        <li><span class="badge rounded-pill bg-secondary">External data joins</span> is the most flexible form of feature engineering. Joining multiple data frames or tables together to add more data. For example, adding simple data like Statistics Canada or Environics reports, or using APIs or other models to add more information to existing dataset (e.g., using Google Maps to translate coordinates into addresses, postal codes, and cities).</li>
                        <li><span class="badge rounded-pill bg-secondary">Scaling data</span>: data transformations (e.g., natural log or squaring a variable) can be used to improve a model. Used if certain patterns are identified in the data.</li>
                    </ul>
                    <p>A <span class="badge rounded-pill bg-secondary">dummy variable</span> or <span class="badge rounded-pill bg-secondary">indicator variable</span> is an artificial variable created to represent an attribute with two or more distinct categories / levels. Regression analysis treats all independent (X) variables as numerical (e.g., interval or ratio scale). This means typically numerical values have a meaning (e.g., 10 is double the amount of 5). You may want to include an attribute or nominal scale variable, like Product Brand or Type of Defect (e.g., you have 3 types of products labeled "1", "2" and "3"; in this case, 3 minus 1 doesn't mean anything significant - this is a dummy variable).</p>
                    <p><em>Example 1:</em> Model specifications.<img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-1.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-2.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-3.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-4.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-5.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-6.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-7.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-8.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-9.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-10.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-11.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-12.PNG" class="mx-auto d-block" alt="Model specifications"><img src="../img/using-python-ii-clean-predict-and-inform/model-specifications-13.PNG" class="mx-auto d-block" alt="Model specifications"></p>
                    <p><em>Example 2:</em> Feature engineering.<img src="../img/using-python-ii-clean-predict-and-inform/feature-engineering-1.PNG" class="mx-auto d-block" alt="Feature engineering"><img src="../img/using-python-ii-clean-predict-and-inform/feature-engineering-2.PNG" class="mx-auto d-block" alt="Feature engineering"></p>
                    <p><em>Example 3:</em> Dummy variables.<img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-1.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-2.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-3.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-4.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-5.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-6.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-7.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-8.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-9.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-10.PNG" class="mx-auto d-block" alt="Dummy variables"><img src="../img/using-python-ii-clean-predict-and-inform/dummy-variables-11.PNG" class="mx-auto d-block" alt="Dummy variables"></p>
                    <p><em>Example 4:</em> Data cleaning, exploratory analysis, and statistical analysis.<img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-1.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-2.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-3.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-4.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-5.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-6.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-7.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-8.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-9.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-10.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-11.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"><img src="../img/using-python-ii-clean-predict-and-inform/data-cleaning-exploratory-analysis-and-statistical-analysis-12.PNG" class="mx-auto d-block" alt="Data cleaning, exploratory analysis, and statistical analysis"></p>
                    <p><em>Example 5:</em> Assignment 3 (selected examples).<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-0.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression">Create dummy variables for the Fuel_Type, Transmission, and Seller_Type variables.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-1a.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-1b.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-1c.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression">Create a new column that captures the age of the car as "new" or "old".<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-2.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression">Scale the Kms_Driven, Selling_Price, and Present_Price variables.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-3.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression">Conduct exploratory analysis for the categorical variables.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4a.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4b.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4c.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4d.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4e.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4f.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4g.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4h.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4i.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4j.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4k.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4l.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-4m.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression">Conduct exploratory analysis for the continuous variables.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5a.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5b.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5c.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5d.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5e.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5f.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5g.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5h.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5i.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5j.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5k.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5l.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5m.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5n.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5o.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5p.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-5q.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression">Build a linear regression model.<img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-6a.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"><img src="../img/using-python-ii-clean-predict-and-inform/assignment-3-6b.PNG" class="mx-auto d-block" alt="Assignment 1 - linear regression"></p>
                </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingFour">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseFour" aria-expanded="true" aria-controls="collapseFour">Drawing Inferences</button>
            </h2>
            <div id="collapseFour" class="accordion-collapse collapse" aria-labelledby="headingFour" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <p>The main purpose of statistics is to test a hypothesis, for example, testing that a drug is effective in treating headaches. A <span class="badge rounded-pill bg-secondary">hypothesis</span> is an educated guess about something in the world around you.</p>
                    <p>When proposing a hypothesis, it is customary to write a statement: <span class="badge rounded-pill bg-secondary">if I do {X - independent variable}, then {Y - dependent variable} will happen</span>. A good hypothesis statement consists of: "if" and "then" statement, both independent and dependent variables, testability by experiment, survey or other technique, based on information from prior research, and design criteria.</p>
                    <p><span class="badge rounded-pill bg-secondary">Hypothesis testing</span> in statistics is a method of determining if the results of a survey or experiment are significant to prove the hypothesis. If the survey or experiments happened by chance (rather than the implemented change), then the experiment is NOT repeatable and therefore has little use.</p>
                    <p>Performing a test requires a <span class="badge rounded-pill bg-secondary">null hypothesis</span>. This refers to the already-accepted-fact. Testing will either prove or disprove the null hypothesis (i.e., accept or reject).</p>
                    <p><em>Example 1:</em> <span class="badge rounded-pill bg-secondary">Problem statement</span>: A researcher thinks that if knee surgery patients go to physical therapy twice a week (instead of 3 times), their recovery period will be longer. Average recovery times for knee surgery patients is 8.2 weeks.<br>
                        <span class="badge rounded-pill bg-secondary">Hypothesis</span>: H<sub>1</sub>: µ &gt; 8.2<br>
                        <span class="badge rounded-pill bg-secondary">Null hypothesis</span>: H<sub>0</sub> µ = 8.2</p>
                    <p>The <span class="badge rounded-pill bg-secondary">p-value</span> is the probability of getting a result as extreme as the one we just calculate (i.e., getting the same result by chance). If the p-value is high, we accept the null hypothesis (i.e., our proposed change does not have significant impact on the outcome). If the p-value is small (below 0.05), we reject the null hypothesis (i.e., we've proven that the proposed change will significantly change the outcome on a repeatable basis). This is also what is meant by <span class="badge rounded-pill bg-secondary">statistically significant</span>.</p>
                    <p>Statistical tests (A/B testing):</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Standard t-test</span>: this is the most basic type of statistical tests, which compares the means from exactly two groups (e.g., control group vs. experimental group).</li>
                        <li><span class="badge rounded-pill bg-secondary">Paired t-test</span>: a test to detect differences (i.e., before and after) where the same individuals are measured after the application of a treatment.</li>
                        <li><span class="badge rounded-pill bg-secondary">One-Way ANOVA</span>: similar to a t-test, except this test compares the means from three or more groups.</li>
                        <li><span class="badge rounded-pill bg-secondary">Two-Way ANOVA</span>: compares the means of two or more groups in response to two different independent variables.</li>
                    </ul>
                    <p>Modeling assumptions:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Linearity</span>: the expected value of the dependent variable is a linear function of each independent variable, holding the others fixed (note this does not restrict you to use a nonlinear transformation of the independent variables; i.e., you can still model f(x) = ax<sup>2</sup> + bx + c, using both x<sup>2</sup> and x as predicting variables).</li>
                        <li><span class="badge rounded-pill bg-secondary">Independence</span>: the errors (residuals of the fitted model) are independent of each other.</li>
                        <li><span class="badge rounded-pill bg-secondary">Homoscedasticity (constant variance)</span>: the variance of the errors is constant with respect to the predicting variables or the response.</li>
                        <li><span class="badge rounded-pill bg-secondary">Normality</span>: the errors are generated from a normal distribution (of unknown mean and variance, which can be estimated from the data). Note, this is not a necessary condition to perform linear regression unlike the top three above. However, without this assumption being satisfied, you cannot calculate the so-called "confidence" or "prediction" intervals easily as the well-known analytical expressions corresponding to Gaussian distribution cannot be used.</li>
                    </ul>
                    <p>Visual tests to evaluate model:</p>
                    <ul>
                        <li>
                            <p><span class="badge rounded-pill bg-secondary">Q-Q plot</span>: a plot of the sorted values from the data set against the expected values of the corresponding quantiles from the standard normal distribution. If the null hypothesis is true, the plotted points should lie approximately on a straight line.</p>
                            <img src="../img/using-python-ii-clean-predict-and-inform/checking-for-normality.PNG" class="mx-auto d-block" alt="Checking for normality"></li>
                        <li>
                            <p><span class="badge rounded-pill bg-secondary">Residuals vs. fitted plot</span>: a plot that tests the assumption of whether the relationship between variables is linear and whether there is equal variance along the regression line (i.e., homoscedasticity). The plot should be shapeless and symmetrically distributed around the 0 line.</p>
                            <img src="../img/using-python-ii-clean-predict-and-inform/residuals-vs-predicting-variables.PNG" class="mx-auto d-block" alt="Residuals vs. predicting variables"><img src="../img/using-python-ii-clean-predict-and-inform/residuals-vs-fitted-plot.PNG" class="mx-auto d-block" alt="Residuals vs. fitted plot"></li>
                        <li>
                            <p><span class="badge rounded-pill bg-secondary">Homoscedasticity (constant variance)</span>: the variance of the errors is constant with respect to the predicting variables or the response.</p>
                            <img src="../img/using-python-ii-clean-predict-and-inform/common-patterns.PNG" class="mx-auto d-block" alt="Common patterns"></li>
                        <li>
                            <p><span class="badge rounded-pill bg-secondary">Scale-location plot</span>: a plot to check the assumption of equal variance in errors. The plot should have a horizontal line with points spread randomly on either side.</p>
                            <img src="../img/using-python-ii-clean-predict-and-inform/scale-location.PNG" class="mx-auto d-block" alt="Scale-location"></li>
                        <li>
                            <p><span class="badge rounded-pill bg-secondary">Residuals vs. leverage plot</span>: a plot to identify observations with high leverage (i.e., that may greatly influence the regression results). Observations outside the dotted red lines have high leverage and should be investigated.</p>
                            <img src="../img/using-python-ii-clean-predict-and-inform/residuals-vs-leverage.PNG" class="mx-auto d-block" alt="Residuals vs. leverage"><img src="../img/using-python-ii-clean-predict-and-inform/potential-outliers.PNG" class="mx-auto d-block" alt="Potential outliers"></li>
                        <li>
                            <p><span class="badge rounded-pill bg-secondary">Density plot</span>: a plot that maps the residual values against a normal distribution. The plot should follow as normal distribution as possible.</p>
                            <img src="../img/using-python-ii-clean-predict-and-inform/density-plot.PNG" class="mx-auto d-block" alt="Density plot"></li>
                    </ul>
                    <p>The <span class="badge rounded-pill bg-secondary">k-nearest neighbors</span>, or <span class="badge rounded-pill bg-secondary">k-NN</span>, algorithm is one of the most widely used classification techniques. It is a part of the supervised machine learning family of algorithms. KNN algorithm analyses the entire dataset and determines the class of a new data point based on similarity measures (e.g., distance function). A new data point is assigned to the class which has the nearest neighbors around this new data point. k is the number of neighbors that the algorithm considers in the calculations. Usually, k is a small positive integer. If k = 1, then the object is simply assigned to the class of that single nearest neighbor.</p>
                    <img src="../img/using-python-ii-clean-predict-and-inform/k-nearest-neighbour-models.PNG" class="mx-auto d-block" alt="K-nearest neighbour models"></div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingFive">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseFive" aria-expanded="true" aria-controls="collapseFive">Data Management Principles, Privacy, and Security</button>
            </h2>
            <div id="collapseFive" class="accordion-collapse collapse" aria-labelledby="headingFive" data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <p><span class="badge rounded-pill bg-secondary">Data privacy</span> refers to the relationship between the collection and the use or disclosure of personal information. Personal information includes:</p>
                    <ul>
                        <li>Personal identifiers (name, address, account number)</li>
                        <li>Behavior information (transactions, products purchased)</li>
                        <li>Preferences and opinions (survey results, reviews)</li>
                        <li>Ratings or assessments (credit score, customer rating)</li>
                        <li>Attributes (health data, insurance claims)</li>
                    </ul>
                    <p>All companies want to understand people better. Having more data allows companies to: customize products and services, influence customer product selection, increase customer loyalty, and anticipate customer behavior (good or bad).</p>
                    <p>The more data companies can collect and use, the faster innovation will be. This is good (customers can receive targeted service and products to fit their needs; interactions will be seamless, administrative burden will be reduced (e.g., ordering products each time)) and bad (companies will have a lot of power and influence over customer choices, companies may misuse data to invade privacy, companies can profit from using customer data).</p>
					<p>10 principles of <span class="badge rounded-pill bg-secondary">PIPEDA</span> (Personal Information Protection and Electronic Documents Act):</p>
                    <ul>
                        <li>Accountability</li>
                        <li>Identifying purposes</li>
                        <li>Consent</li>
                        <li>Limiting collection</li>
                        <li>Limiting collection, use, disclosure</li>
                        <li>Accuracy</li>
                        <li>Safeguards</li>
                        <li>Openness</li>
                        <li>Individual access</li>
                        <li>Challenging compliance</li>
                    </ul>
					<p>The goal of <span class="badge rounded-pill bg-secondary">data security</span>:</p>
                    <ul>
                        <li><span class="badge rounded-pill bg-secondary">Confidentiality</span>: data is only used by the people who need it.</li>
                        <li><span class="badge rounded-pill bg-secondary">Integrity</span>: changes to data are only made by authorized users.</li>
                        <li><span class="badge rounded-pill bg-secondary">Availability</span>: data is available when needed by authorized persons.</li>
                    </ul>
					<p><span class="badge rounded-pill bg-secondary">Data management</span> is the process of ingesting, storing, organizing, and maintaining all organizational data. <span class="badge rounded-pill bg-secondary">Data governance</span> is the oversight of data management practices.</p>
                    <p>Data management programs:</p>
                    <ul>
                        <li>Data quality (accuracy, formatting, timeliness)</li>
                        <li>Metadata management (data about data: date recorded, last maintenance, who recorded the data, file size, etc.)</li>
                        <li>Data lifecycle management (standards for storage and disposal of data)</li>
                        <li>Master reference data (major groups of data to create a consistent reference point (e.g., customer data, operational data, etc.))</li>
                    </ul>
					<p><span class="badge rounded-pill bg-secondary">Data stewards</span> oversee the implementation of data management practices in an organization.</p>
                    <p><em>Example 1:</em><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-1.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-2.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-3.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-4.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-5.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-6.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-7.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-8.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-9.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-10.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-11.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"><img src="../img/using-python-ii-clean-predict-and-inform/ab-nyc-2019-12.PNG" class="mx-auto d-block" alt="Analysis of Airbnb data in NYC 2019"></p>
                </div>
            </div>
        </div>
    </div>
</div>
<script src="../js/"></script> 
<script src="../js/bootstrap.min.js"></script>
</body>
</html>